---
title: forbes_ua_trends
description: |
  A short description of the post.
author: Vadym Yudneko
date: 2023-08-01
draft: true
categories:
  - webscrapping
  - text mining
  - google trends
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

# Forbes

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# # Load necessary packages
# library(rvest)
# library(dplyr)
# library(purrr)
# library(gtrendsR)
# library(car)
# library(pbapply)
# library(tidytext)
# library(stringr)
# library(tm)
# library(lubridate)
# 
# stopwords <- read.delim("stopwords_ua.txt", header = F)
# # Initialize empty vectors to store the dates and messages
# dates <- c()
# messages <- c()
# 
# # Define the file name
# file_name <- "messages1.html"
# 
# # Read the HTML file
# html_data <- read_html(file_name)
# 
# # Scrape all messages
# all_messages <- html_data %>% 
#   html_nodes(".message.default.clearfix.joined, .message.default.clearfix")
# 
# # Loop through all messages
# for(i in 1:length(all_messages)){
#   # Try to scrape the date and message text
#   date <- all_messages[i] %>% html_node(".pull_right.date.details") %>% html_attr("title")
#   message <- all_messages[i] %>% html_node(".text") %>% html_text()
# 
#   # Add the date and message text to the vectors
#   dates <- c(dates, date)
#   messages <- c(messages, message)
#   
#   # Print progress every 100 messages
#   if(i %% 100 == 0){
#     print(paste0("Processed ", i, " messages"))
#   }
# }
# 
# # Combine into a data frame
# df <- data.frame(Date = dates, Message = messages)
# df_copy <- df
```

```{r telegram}
# # Assuming your data frame is named 'df', replace it with the actual name of your data frame
# # You should have two columns: 'date' and 'text'
# df <- df_copy
# # Convert the 'date' column to a proper date format (if not already)
# df$Date <- as.POSIXct(df$Date, format = "%d.%m.%Y %H:%M:%S")
# 
# # Remove NAs from the 'text' column
# df <- df %>%
#   filter(!is.na(Message))
# 
# # Convert all Messages to lowercase (optional but can be useful for analysis)
# df$Message <- tolower(df$Message)
# 
# # Clean the Messages by removing punctuation and special characters
# df$Message <- df$Message %>%
#   str_replace_all("[^[:alnum:]\\s]", " ") %>% # Replace non-alphanumeric characters with a space
#   str_replace_all("\\s+", " ") # Remove extra spaces
# 
# # Tokenize the Messages
# df <- df %>%
#   unnest_tokens(word, text, token = "tweets")
```

# Gtrends

```{r}
# # https://en.wikipedia.org/wiki/ISO_3166-2:UA
# gt_regions <- c("UA-71", 
#           "UA-74", 
#           "UA-77", 
#           "UA-12", 
#           "UA-14", 
#           "UA-26", 
#           "UA-63",
#           "UA-65",
#           "UA-68",
#           "UA-32", 
#           "UA-35", 
#           "UA-09",
#           "UA-46",
#           "UA-48",
#           "UA-51",
#           "UA-53",
#           "UA-56",
#           "UA-59",
#           "UA-61",
#           "UA-05",
#           "UA-07",
#           "UA-21",
#           "UA-23",
#           "UA-18",
#           "UA-30",
#           "UA-40",
#           "UA-43")
# gt_topic_codes <- c('/m/06l8d','/m/09j2d','/m/0h6dlrc','/m/02vqfm','/m/02crq1')
# gt_topic_names <- c("Restaurant","Clothing","BMW","Coffee","Couch")
# gt_waiting_time <- 30
# gt_time <- '2018-01-01 2023-08-01'
# data <- data.frame(matrix(ncol = 7, nrow = 0))
# for (i in 1:length(gt_regions)){
#  for (j in 1:length(gt_topic_codes)){
#       temp <- tryCatch({
#      gtrends(gt_topic_codes[j], geo = gt_regions[i], time = gt_time)
#      }, error = function(cond) {
#        blanktemp <- temp
#        blanktemp$hits <- 0
#        blanktemp$keyword <- gt_topic_names[j]
#        blanktemp$geo <- gt_regions[i]
#        return(blanktemp)
#      })
#    temp <- temp[["interest_over_time"]]
#    temp["keyword"][temp["keyword"] == gt_topic_codes[j]] =  gt_topic_names[j]
#    data <- rbind(data, temp)
#    Sys.sleep(gt_waiting_time)
#  }
# }
# 
# #data <- read.csv("consumer_index.csv") #commited the wrong file initially
# 
# # consumer index
# consumer_index <- data %>%
#   group_by(geo, date) %>%
#   summarise(consumer_index = sum(hits)) %>%
#   ungroup()
# region_names <- data.frame(
#   geo = c("UA-71", 
#           "UA-74", 
#           "UA-77", 
#           "UA-12", 
#           "UA-14", 
#           "UA-26", 
#           "UA-63",
#           "UA-65",
#           "UA-68",
#           "UA-32", 
#           "UA-35", 
#           "UA-09",
#           "UA-46",
#           "UA-48",
#           "UA-51",
#           "UA-53",
#           "UA-56",
#           "UA-59",
#           "UA-61",
#           "UA-05",
#           "UA-07",
#           "UA-21",
#           "UA-23",
#           "UA-18",
#           "UA-30",
#           "UA-40",
#           "UA-43"),
#   region = c("Cherkasy", 
#              "Chernihiv", 
#              "Chernivtsi", 
#              "Dnipropetrovsk", 
#              "Donetsk", 
#              "Ivano-Frankivsk", 
#              "Kharkiv", 
#              "Kherson", 
#              "Khmelnytskyi", 
#              "Kiev", 
#              "Kirovohrad", 
#              "Luhansk", 
#              "Lviv", 
#              "Mykolaiv", 
#              "Odessa", 
#              "Poltava", 
#              "Rivne", 
#              "Sumy", 
#              "Ternopil", 
#              "Vinnytsia", 
#              "Volyn", 
#              "Zakarpattia",
#              "Zaporizhia",
#              "Zhytomyr", 
#              "Kyiv City", 
#              "Sevastopol' city", 
#              "Crimea")
# )
# consumer_index <- consumer_index %>%
#   left_join(region_names, by = "geo") %>%
#   select(-geo)
# 
# write.csv(consumer_index, "consumer_index.csv",  row.names = FALSE)
```

```{# {r}
# library(rvest)
# 
# # The URL of the web page
# url <- 'https://www.google.com/maps/d/u/0/viewer?mid=10n5IOLu0m7G1jSSKxLXgXPznoGjn7MMO&ll=49.049796668933965%2C30.152437113599326&z=5'
# 
# # Load the page
# page <- read_html(url)
# 
# # Extract the scripts
# scripts <- html_nodes(page, 'script')
# 
# # Extract the contents of the scripts as text
# scripts_text <- html_text(scripts)
# 
# # Find the script that contains the _pageData variable
# page_data_script <- grep('_pageData', scripts_text, value=TRUE)
# 
# # Use a regular expression to extract the value of the _pageData variable
# # This assumes that the variable is assigned using JSON syntax, like _pageData = {...}
# page_data <- sub('.*_pageData = (.*);.*', '\\1', page_data_script)
# 
# # Now page_data contains the value of the _pageData variable as a string
# # You can parse this string as JSON or CSV, depending on the format
# 
# parsed_data <- read.csv(text = page_data)
```

```{r}
# mun_sd <- highlight_key(mun_acs_calc, ~municipality, group = "Municpality")
# 
# # mun_sd <- mun_acs_calc %>% 
# #   SharedData$new()
# 
# p <- mun_sd %>% 
#   ggplot(aes(poverty_pct, total_cases_per_cap)) +
#   geom_point(
#     aes(
#       size = total_pop,
#       text = paste0(
#         "<b>", municipality, "</b><br>",
#         "Families below 200% poverty line: ", percent(poverty_pct, 1), "<br>",
#         "Share of population with positive test: ", pretty_frac(total_cases_per_cap)
#         )
#       ),
#     shape = 21,
#     color = "steelblue",
#     fill = adjustcolor("steelblue", alpha.f = 0.3),
#     alpha = 0.9
#     ) +
#   expand_limits(x = 0, y = 0.05) + 
#   scale_x_continuous(label = label_percent(1)) +
#   scale_y_continuous(label = label_percent(1), breaks = seq(0, 0.5, by = 0.05)) + 
#   scale_size(trans = "log10", range = c(1, 5)) +
#   labs(
#     x = "Families below 200% of poverty line",
#     y = "Total population with positive test"
#   ) +
#   theme_minimal() +
#   theme(axis.title.x = element_text(size = 14))
# 
# p_plotly <- ggplotly_config(p)
# 
# p2 <- mun_sd %>%
#   ggplot(aes(crowded_pct, total_cases_per_cap)) +
#   geom_point(
#     aes(
#       size = total_pop,
#       text = paste0(
#         "<b>", municipality, "</b><br>",
#         "Overcrowded households: ", percent(crowded_pct, 1), "<br>",
#         "Share of population with positive test: ", pretty_frac(total_cases_per_cap)
#         )
#       ),
#     shape = 21,
#     color = "steelblue",
#     fill = adjustcolor("steelblue", alpha.f = 0.3),
#     alpha = 0.9
#     ) +
#   expand_limits(x = 0, y = 0.05) + 
#   scale_x_continuous(label = label_percent(1), breaks = c(0, 0.05, 0.1)) +
#   scale_y_continuous(label = label_percent(1), breaks = seq(0, 0.5, by = 0.05)) + 
#   scale_size(trans = "log10", range = c(1, 5)) +
#   labs(
#     x = "Overcrowded households",
#     y = "Total population with positive test"
#   ) +
#   theme_minimal() +
#   theme(axis.title.x = element_text(size = 14))
# 
# p2_plotly <- ggplotly_config(p2)
# 
# p3 <- mun_sd %>%
#   ggplot(aes(black_lat_pct, total_cases_per_cap)) +
#   geom_point(
#     aes(
#       size = total_pop,
#       text = paste0(
#         "<b>", municipality, "</b><br>",
#         "Black or Latino population: ", percent(black_lat_pct, 1), "<br>",
#         "Share of population with positive test: ", pretty_frac(total_cases_per_cap)
#         )
#       ),
#     shape = 21,
#     color = "steelblue",
#     fill = adjustcolor("steelblue", alpha.f = 0.3),
#     alpha = 0.9
#     ) +
#   expand_limits(x = 0, y = 0.05) + 
#   scale_x_continuous(label = label_percent(1)) +
#   scale_y_continuous(label = label_percent(1), breaks = seq(0, 0.5, by = 0.05)) + 
#   scale_size(trans = "log10", range = c(1, 5)) +
#     labs(
#     x = "Black or Latino population",
#     y = "Total population with positive test"
#   ) +
#   theme_minimal() +
#   theme(axis.title.x = element_text(size = 14))
# 
# p3_plotly <- ggplotly_config(p3)


# label_frac <- function(x, accuracy = NULL) {
#     function(x) pretty_frac(x, accuracy = accuracy)
#     }
#   
# 
# p4 <- mun_sd %>%
#   ggplot(aes(hs_less_pct, total_cases_per_cap)) +
#   geom_point(
#     aes(
#       size = total_pop,
#       text = paste0(
#         "<b>", municipality, "</b><br>",
#         "Black or Latino population: ", percent(hs_less_pct, 1), "<br>",
#         "Share of population with positive test: ", pretty_frac(total_cases_per_cap)
#         )
#       ),
#     shape = 21,
#     color = "steelblue",
#     fill = adjustcolor("steelblue", alpha.f = 0.3),
#     alpha = 0.9
#     ) +
#   expand_limits(x = 0, y = 0.02) + 
#   scale_x_continuous(label = label_percent(1)) +
#   scale_y_continuous(label = label_frac(1), breaks = seq(0, 0.2, by = 0.02)) + 
#   scale_size(trans = "log10", range = c(1, 5)) +
#     labs(
#     x = "Black or Latino population",
#     y = "Total population with positive test"
#   ) +
#   theme_minimal() +
#   theme(axis.title.x = element_text(size = 14))
# 
# p4_plotly <- ggplotly_config(p4)

# scatter <- list(p_plotly, p2_plotly, p3_plotly)
```
